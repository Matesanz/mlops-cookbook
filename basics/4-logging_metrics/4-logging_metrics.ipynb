{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Metrics\n",
    "\n",
    "In MLflow, you can log various types of data related to your experiments and runs. These logged data are crucial for tracking and understanding your machine learning processes. The main types of data that can be logged in MLflow include:\n",
    "\n",
    "1. **Tags and Notes**: You can add tags and notes to your \"runs\" to provide additional information and context about what you're doing in that specific experiment. This makes it easier to search and understand your \"runs\" in the future.\n",
    "\n",
    "2. **Parameters**: These are configurable values used in the execution of a \"run.\" For example, the learning rate, maximum depth of a decision tree, or any other value that affects the behavior of your model.\n",
    "\n",
    "3. **Metrics**: Metrics are quantitative measures of your model's performance. You can log metrics such as accuracy, mean squared error (MSE), logarithmic loss, etc. These metrics help you evaluate and compare the performance of different \"runs\" and approaches.\n",
    "\n",
    "Logging these types of data in MLflow helps you maintain a detailed record of your experiments and enables you to analyze, compare, and effectively share your results. This is essential for the development of machine learning models as it allows you to understand which approaches work best and how to improve your work over time.\n",
    "\n",
    "![mlflow_frontend](/assets/mlflow_frontend.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: f7773173fca64d02bc55974d3c7762bb\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "\n",
    "EXPERIMENT_NAME = \"mlflow-demo\"  #  ‚ùó make sure this experiment exists\n",
    "RUN_NAME = \"run-with-metrics\"\n",
    "\n",
    "\n",
    "experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "\n",
    "\n",
    "with mlflow.start_run(\n",
    "    experiment_id=experiment_id,\n",
    "    run_name=RUN_NAME,\n",
    ") as run:\n",
    "    \n",
    "    # set the tags\n",
    "    mlflow.set_tags({\n",
    "        \"model\": \"linear-regression\",\n",
    "        \"author\": \"mlops-course\",\n",
    "    })\n",
    "    \n",
    "    # Log a parameter (key-value pair)\n",
    "    # Log the model parameters\n",
    "    mlflow.log_param(\"random_seed\", 42)\n",
    "    mlflow.log_param(\"train_size\", 0.7)\n",
    "\n",
    "    # Model training code here ...\n",
    "\n",
    "    # Log a metric; metrics can be updated throughout the run\n",
    "    mlflow.log_metric(\"precision\", 0.92)\n",
    "    mlflow.log_metric(\"recall\", 0.96)\n",
    "\n",
    "    # Print the run ID\n",
    "    print(f\"Run ID: {run.info.run_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
