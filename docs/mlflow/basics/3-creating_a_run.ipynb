{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Run\n",
    "\n",
    "In the context of MLflow, a \"run\" refers to a **specific instance of an experiment**. You can think of a \"run\" as a unique execution of an experiment, where specific configurations are applied, a model is trained with particular data, and results are recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ Run ID: ee728d1da7e84c6e939b464419d9b85a\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "\n",
    "# Set the experiment name\n",
    "experiment = mlflow.set_experiment(\"mlflow-demo\")\n",
    "\n",
    "# Start a new run\n",
    "experiment_id = experiment.experiment_id\n",
    "with mlflow.start_run(experiment_id=experiment_id) as run:\n",
    "    print(f\"ðŸŽ‰ Run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Run?\n",
    "\n",
    "Every time you perform a test, adjust parameters, or use a specific dataset within your MLflow experiment, you are creating a new \"run\" within that experiment. Each \"run\" keeps a detailed record of how parameters were configured, which data was used, and what results were obtained in that particular execution. In MLflow you can see all the runs within an experiment and compare them to determine which one is the most effective based on performance metrics and results.\n",
    "\n",
    "![mlflow_frontend](../../assets/mlflow_frontend.jpg)\n",
    "\n",
    "The ability to track and compare multiple \"runs\" within the same experiment is valuable because it allows you to explore different approaches and settings, record the details of each attempt, and determine which one is the most effective based on performance metrics and results. In summary, a \"run\" in MLflow is an individual instance of an experiment that helps you keep an accurate track of your tests and progress in your machine learning project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-cookbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
